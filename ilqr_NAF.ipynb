{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f160c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.autograd.functional as Fu\n",
    "from functorch import vmap, hessian, jacfwd\n",
    "STATELEN = 5\n",
    "ACTLEN = 3\n",
    "STEP_SIZE = 4\n",
    "#based on https://homes.cs.washington.edu/~todorov/papers/TassaIROS12.pdf\n",
    "class Dynamics(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Dynamics, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "        self.freeze = 0\n",
    "        # we have to freeze at estimate because we have to use vmap for batch training\n",
    "    def forward(self, input_element):\n",
    "        output = self.linear_relu_stack(input_element)\n",
    "        return output\n",
    "    \n",
    "class reward(nn.Module):\n",
    "    #NAF\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(reward, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "    def forward(self, input_element):\n",
    "        output = self.linear_relu_stack(input_element)\n",
    "        return output\n",
    "\n",
    "class policy(nn.Module):\n",
    "    #global\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(reward, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "    def forward(self, input_element):\n",
    "        output = self.linear_relu_stack(input_element)\n",
    "        return output\n",
    "    \n",
    "    #torch.distributions.multivariate_normal.MultivariateNormal\n",
    "    #MultivariateNormal(torch.zeros(2), torch.eye(2)) #psd\n",
    "class ilqr:\n",
    "    \n",
    "    def __init__(self, ts, dyn, re, sl, al, b_s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ts: time step\n",
    "            dyn: dynamic\n",
    "            re: reward\n",
    "            sl: state length\n",
    "            al: action length\n",
    "        \"\"\"\n",
    "        self.ts = ts\n",
    "        self.dyn = dyn\n",
    "        self.re = re\n",
    "        self.sl = sl\n",
    "        self.al = al\n",
    "        self.b_s = b_s\n",
    "        \n",
    "        self.S = torch.zeros((self.ts, self.b_s, self.sl))\n",
    "        self.A = torch.zeros((self.ts, self.b_s, self.al))\n",
    "        self.R = torch.empty((self.ts, self.b_s, 1))\n",
    "        self.K_arr = torch.zeros(self.ts, self.b_s, self.al, self.sl)\n",
    "        self.k_arr = torch.zeros(self.ts, self.b_s, 1, self.al)\n",
    "        self.ifconv = 0\n",
    "        \n",
    "\n",
    "    def _get_batch_reward(self, state_action):\n",
    "        \n",
    "        state, action = torch.split(state_action, [self.sl, self.al], dim=-1)\n",
    "        pre_psd, bias, value = torch.split(self.re(state), [self.al**2, self.al, 1], dim=-1)\n",
    "        \n",
    "        pre_psd = torch.reshape(pre_psd, (self.b_s, self.al, self.al))\n",
    "        pre_psd_trans = torch.transpose(pre_psd, 1, 2)\n",
    "        psd = torch.matmul(pre_psd, pre_psd_trans)\n",
    "        \n",
    "        a_b = (action - bias).unsqueeze(1)\n",
    "        a_b_t = torch.transpose(a_b,1,2)\n",
    "        return value - torch.matmul(torch.matmul(a_b,psd),a_b_t).squeeze(-1)\n",
    "        \n",
    "    def _get_reward(self, state_action):\n",
    "        \n",
    "        state, action = torch.split(state_action, [self.sl, self.al], dim=-1)\n",
    "        pre_psd, bias, value = torch.split(self.re(state), [self.al**2, self.al, 1], dim=-1)\n",
    "        \n",
    "        pre_psd = torch.reshape(pre_psd, (self.al, self.al))\n",
    "        pre_psd_trans = torch.transpose(pre_psd, 0, 1)\n",
    "        psd = torch.matmul(pre_psd, pre_psd_trans)\n",
    "        \n",
    "        a_b = (action - bias).unsqueeze(1)\n",
    "        a_b_t = torch.transpose(a_b,0,1)\n",
    "        return value.squeeze() - torch.matmul(torch.matmul(a_b_t,psd),a_b).squeeze()\n",
    "    \n",
    "    def _forward(self):\n",
    "        \n",
    "        new_S = torch.zeros((self.ts, self.b_s, self.sl))\n",
    "        new_A = torch.zeros((self.ts, self.b_s, self.al))\n",
    "        s = self.S[0].clone().detach()\n",
    "        #for p in self.dyn.parameters():\n",
    "        #    print(p)\n",
    "        i = 0\n",
    "        while i < self.ts:\n",
    "            new_S[i] = s\n",
    "            state_difference = (new_S[i] - self.S[i]).unsqueeze(1)\n",
    "            \n",
    "            state_action_trans = torch.matmul(state_difference,torch.transpose((self.K_arr[i]),1,2))\n",
    "            \n",
    "            new_A[i] = (state_action_trans + self.k_arr[i]).squeeze(1) + self.A[i]\n",
    "            sa_in = torch.cat((new_S[i], new_A[i]),dim = 1)\n",
    "            \n",
    "            s = self.dyn(sa_in)\n",
    "\n",
    "            #state shape = [1,state_size]\n",
    "\n",
    "            self.R[i] = self._get_batch_reward(sa_in)\n",
    "            \n",
    "            i = i + 1\n",
    "        self.S = new_S\n",
    "        self.A = new_A\n",
    "\n",
    "    def _backward(self):\n",
    "        \n",
    "        C = torch.zeros(self.b_s, self.al + self.sl, self.al + self.sl)\n",
    "        F = torch.zeros(self.b_s, self.sl, self.al + self.sl)\n",
    "        c = torch.zeros(self.b_s, 1, self.al + self.sl)\n",
    "        V = torch.zeros(self.b_s, self.sl, self.sl)\n",
    "        v = torch.zeros(self.b_s, 1, self.sl)\n",
    "        sa_in = torch.cat((self.S, self.A),dim = -1)\n",
    "        \n",
    "        i = self.ts -1\n",
    "        while i > -1:\n",
    "\n",
    "            C = vmap(hessian(self._get_reward))(sa_in[i])\n",
    "            #shape = [state+action, state+action]\n",
    "            #print(torch.sum(C[j]))\n",
    "            c = vmap(jacfwd(self._get_reward))(sa_in[i])\n",
    "            \n",
    "            #shape = [1, state+action]\n",
    "            #print(torch.sum(c[j]))\n",
    "            F = vmap(jacfwd(self.dyn))(sa_in[i])\n",
    "            #shape = [state, state+action]\n",
    "            #print(torch.sum(F[j]))\n",
    "            # use jacfwd because input is large than output\n",
    "            transF = torch.transpose(F,1,2)\n",
    "            Q = C + torch.matmul(torch.matmul(transF, V), F)\n",
    "\n",
    "            #eq 5[c~e]\n",
    "            q = c.unsqueeze(1) + torch.matmul(v, F)\n",
    "\n",
    "            #eq 5[a~b]\n",
    "            \n",
    "            Q_pre1, Q_pre2 = torch.split(Q, [self.sl, self.al], dim = 1)\n",
    "            Q_xx, Q_xu = torch.split(Q_pre1, [self.sl, self.al], dim = 2)\n",
    "            Q_ux, Q_uu = torch.split(Q_pre2, [self.sl, self.al], dim = 2)\n",
    "            \n",
    "            Q_x, Q_u = torch.split(q, [self.sl, self.al], dim = -1)\n",
    "            ## how to batched eye?\n",
    "            #print(Q_uu)\n",
    "            try:\n",
    "                invQuu = torch.linalg.inv(Q_uu - torch.eye(self.al)*0.01)# - torch.eye(self.al)) #regularize term\n",
    "                #eq [9]\n",
    "            except:\n",
    "                invQuu = torch.linalg.inv(Q_uu + torch.eye(self.al)*0.01)\n",
    "                self.ifconv = 1\n",
    "\n",
    "            K = -torch.matmul(invQuu, Q_ux)\n",
    "            transK = torch.transpose(K, 1, 2)\n",
    "            #K_t shape = [actlen, statelen]\n",
    "\n",
    "            k = -torch.matmul(Q_u, invQuu)\n",
    "            #k_t shape = [1,actlen]\n",
    "\n",
    "            V = (Q_xx + torch.matmul(Q_xu, K) + \n",
    "                 torch.matmul(transK, Q_ux) +\n",
    "                 torch.matmul(torch.matmul(transK, Q_uu), K)\n",
    "                )\n",
    "            # eq 11c\n",
    "            #V_t shape = [statelen, statelen]\n",
    "\n",
    "            v = (Q_x + torch.matmul(k, Q_ux) + \n",
    "                 torch.matmul(Q_u, K) + \n",
    "                 torch.matmul(k, torch.matmul(Q_uu, K)) \n",
    "                )\n",
    "            # eq 11b\n",
    "            #v_t shape = [1, statelen]\n",
    "            \n",
    "            self.K_arr[i] = K\n",
    "            self.k_arr[i] = k\n",
    "            i = i - 1\n",
    "    \n",
    "    def fit(self, action, state):\n",
    "        self.A = action\n",
    "        self.S[0] = state[0]\n",
    "        setattr(self.dyn,'freeze',1)\n",
    "        i = 0\n",
    "        while (self.ifconv != 1) and i < 100:\n",
    "            i = i + 1\n",
    "            self._forward()\n",
    "            self._backward()\n",
    "\n",
    "            print(\"act\",self.A)\n",
    "        return self.A\n",
    "\n",
    "# for param in rew.parameters():\n",
    "#    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "036a84a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[0.2277, 0.0591, 0.4367],\n",
      "         [0.2343, 0.0996, 0.5524],\n",
      "         [0.6383, 0.5095, 0.2959],\n",
      "         [0.9270, 0.1393, 0.2315],\n",
      "         [0.2984, 0.8681, 0.5585]],\n",
      "\n",
      "        [[0.1134, 0.5634, 0.9828],\n",
      "         [0.5259, 0.5961, 0.5791],\n",
      "         [0.9666, 0.1994, 0.2510],\n",
      "         [0.8835, 0.1216, 0.4629],\n",
      "         [0.0057, 0.6606, 0.3636]],\n",
      "\n",
      "        [[0.3954, 0.4540, 0.9163],\n",
      "         [0.5561, 0.0212, 0.5205],\n",
      "         [0.4214, 0.3996, 0.4864],\n",
      "         [0.5211, 0.3082, 0.6915],\n",
      "         [0.2225, 0.4429, 0.8786]],\n",
      "\n",
      "        [[0.1925, 0.8807, 0.0220],\n",
      "         [0.3093, 0.9303, 0.1509],\n",
      "         [0.1140, 0.2144, 0.6088],\n",
      "         [0.8726, 0.6869, 0.5256],\n",
      "         [0.0149, 0.3884, 0.9895]],\n",
      "\n",
      "        [[0.5366, 0.7609, 0.3623],\n",
      "         [0.1822, 0.7380, 0.1089],\n",
      "         [0.3387, 0.1850, 0.9478],\n",
      "         [0.0949, 0.3342, 0.2674],\n",
      "         [0.8427, 0.2960, 0.9518]],\n",
      "\n",
      "        [[0.6852, 0.1004, 0.2906],\n",
      "         [0.0518, 0.4252, 0.0247],\n",
      "         [0.3832, 0.3733, 0.0714],\n",
      "         [0.8320, 0.8992, 0.8441],\n",
      "         [0.3424, 0.5108, 0.9458]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.4210,  0.3125, -0.1524],\n",
      "         [ 0.5991,  0.1554,  0.2758],\n",
      "         [ 0.6763,  0.0892,  0.4487],\n",
      "         [ 0.7028,  0.0660,  0.5051],\n",
      "         [-0.5524,  1.2323, -2.3964]],\n",
      "\n",
      "        [[ 0.8902, -0.2033,  0.8639],\n",
      "         [ 0.7423, -0.0279,  0.5183],\n",
      "         [ 0.6726,  0.0534,  0.3559],\n",
      "         [ 0.7965, -0.0781,  0.6405],\n",
      "         [ 0.6879, -0.0208,  0.3556]],\n",
      "\n",
      "        [[ 0.5477,  0.1948,  0.0325],\n",
      "         [ 0.6415,  0.0848,  0.2703],\n",
      "         [ 0.8066, -0.0981,  0.6732],\n",
      "         [ 0.7155,  0.0155,  0.4605],\n",
      "         [ 0.5498,  0.1922,  0.0337]],\n",
      "\n",
      "        [[ 0.3536,  0.3688, -0.3978],\n",
      "         [ 0.4612,  0.2655, -0.1426],\n",
      "         [ 0.5838,  0.1459,  0.1378],\n",
      "         [ 0.8004, -0.0783,  0.6452],\n",
      "         [ 0.7391, -0.0402,  0.5079]],\n",
      "\n",
      "        [[ 0.5948,  0.1309,  0.1759],\n",
      "         [ 0.5082,  0.2169, -0.0294],\n",
      "         [ 0.8699, -0.1692,  0.8195],\n",
      "         [ 0.3776,  0.3663, -0.3571],\n",
      "         [ 0.7805, -0.0577,  0.5801]],\n",
      "\n",
      "        [[ 0.5900,  0.1354,  0.1538],\n",
      "         [ 0.3492,  0.3802, -0.4099],\n",
      "         [ 0.4336,  0.2967, -0.2099],\n",
      "         [ 0.5598,  0.1667,  0.0713],\n",
      "         [ 0.6080,  0.1320,  0.1943]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 5.1218e-01,  2.1815e-01,  6.9199e-02],\n",
      "         [ 6.6308e-01,  9.6564e-02,  4.1902e-01],\n",
      "         [ 7.2331e-01,  4.8073e-02,  5.5850e-01],\n",
      "         [ 7.4016e-01,  3.4794e-02,  5.9738e-01],\n",
      "         [-3.2672e-01,  8.9648e-01, -1.8766e+00]],\n",
      "\n",
      "        [[ 9.4180e-01, -2.3316e-01,  9.9014e-01],\n",
      "         [ 8.2062e-01, -1.0835e-01,  7.0394e-01],\n",
      "         [ 7.5892e-01, -4.5410e-02,  5.5951e-01],\n",
      "         [ 8.5984e-01, -1.4514e-01,  7.9213e-01],\n",
      "         [ 7.8334e-01, -9.5058e-02,  6.2272e-01]],\n",
      "\n",
      "        [[ 6.5270e-01,  6.2143e-02,  3.0664e-01],\n",
      "         [ 7.3744e-01, -2.4265e-02,  5.0500e-01],\n",
      "         [ 8.7403e-01, -1.6133e-01,  8.2219e-01],\n",
      "         [ 7.9283e-01, -7.7293e-02,  6.3136e-01],\n",
      "         [ 6.4706e-01,  6.6894e-02,  2.9575e-01]],\n",
      "\n",
      "        [[ 4.8741e-01,  2.2243e-01, -6.9810e-02],\n",
      "         [ 5.8377e-01,  1.2746e-01,  1.5249e-01],\n",
      "         [ 6.7690e-01,  3.8228e-02,  3.6420e-01],\n",
      "         [ 8.6743e-01, -1.5369e-01,  8.0644e-01],\n",
      "         [ 8.1436e-01, -1.0444e-01,  6.8864e-01]],\n",
      "\n",
      "        [[ 7.2139e-01, -1.7066e-02,  4.7805e-01],\n",
      "         [ 6.4693e-01,  5.9164e-02,  3.0276e-01],\n",
      "         [ 9.3872e-01, -2.3026e-01,  9.7704e-01],\n",
      "         [ 5.1760e-01,  1.9283e-01, -1.0396e-03],\n",
      "         [ 8.5942e-01, -1.4704e-01,  7.8682e-01]],\n",
      "\n",
      "        [[ 5.3727e-01,  1.8980e-01,  3.1110e-02],\n",
      "         [ 3.4029e-01,  3.8517e-01, -4.2431e-01],\n",
      "         [ 4.0821e-01,  3.1928e-01, -2.6527e-01],\n",
      "         [ 5.1134e-01,  2.1284e-01, -2.7486e-02],\n",
      "         [ 5.4925e-01,  1.7945e-01,  5.8530e-02]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.5905,  0.1549,  0.2509],\n",
      "         [ 0.7109,  0.0582,  0.5297],\n",
      "         [ 0.7581,  0.0203,  0.6390],\n",
      "         [ 0.7690,  0.0118,  0.6642],\n",
      "         [-0.1099,  0.7184, -1.3725]],\n",
      "\n",
      "        [[ 0.9758, -0.2638,  1.0655],\n",
      "         [ 0.8803, -0.1660,  0.8402],\n",
      "         [ 0.8290, -0.1141,  0.7204],\n",
      "         [ 0.9088, -0.1926,  0.9039],\n",
      "         [ 0.8613, -0.1703,  0.8092]],\n",
      "\n",
      "        [[ 0.7474, -0.0309,  0.5235],\n",
      "         [ 0.8153, -0.1000,  0.6825],\n",
      "         [ 0.9204, -0.2051,  0.9262],\n",
      "         [ 0.8520, -0.1349,  0.7657],\n",
      "         [ 0.7381, -0.0221,  0.5035]],\n",
      "\n",
      "        [[ 0.6063,  0.1051,  0.2047],\n",
      "         [ 0.6878,  0.0254,  0.3912],\n",
      "         [ 0.7560, -0.0393,  0.5452],\n",
      "         [ 0.9148, -0.1986,  0.9130],\n",
      "         [ 0.8700, -0.1569,  0.8142]],\n",
      "\n",
      "        [[ 0.8262, -0.1198,  0.7185],\n",
      "         [ 0.7656, -0.0577,  0.5757],\n",
      "         [ 0.9876, -0.2761,  1.0862],\n",
      "         [ 0.6526,  0.0591,  0.3094],\n",
      "         [ 0.9257, -0.2112,  0.9375]],\n",
      "\n",
      "        [[ 0.4935,  0.2342, -0.0699],\n",
      "         [ 0.3344,  0.3914, -0.4365],\n",
      "         [ 0.3886,  0.3388, -0.3099],\n",
      "         [ 0.4743,  0.2512, -0.1136],\n",
      "         [ 0.5024,  0.2260, -0.0492]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 6.5253e-01,  1.0518e-01,  3.9458e-01],\n",
      "         [ 7.4675e-01,  2.9627e-02,  6.1268e-01],\n",
      "         [ 7.8325e-01,  3.5324e-04,  6.9713e-01],\n",
      "         [ 7.9010e-01, -4.9658e-03,  7.1295e-01],\n",
      "         [ 8.6192e-02,  5.5993e-01, -9.1758e-01]],\n",
      "\n",
      "        [[ 9.9788e-01, -2.8365e-01,  1.1139e+00],\n",
      "         [ 9.2375e-01, -2.0784e-01,  9.3920e-01],\n",
      "         [ 8.8241e-01, -1.6604e-01,  8.4268e-01],\n",
      "         [ 9.4418e-01, -2.2677e-01,  9.8469e-01],\n",
      "         [ 9.1953e-01, -2.2323e-01,  9.4819e-01]],\n",
      "\n",
      "        [[ 8.2021e-01, -1.0194e-01,  6.8969e-01],\n",
      "         [ 8.7296e-01, -1.5563e-01,  8.1337e-01],\n",
      "         [ 9.5232e-01, -2.3490e-01,  9.9723e-01],\n",
      "         [ 8.9614e-01, -1.7757e-01,  8.6584e-01],\n",
      "         [ 8.0906e-01, -9.1078e-02,  6.6463e-01]],\n",
      "\n",
      "        [[ 7.0302e-01,  1.0545e-02,  4.2655e-01],\n",
      "         [ 7.6899e-01, -5.3590e-02,  5.7678e-01],\n",
      "         [ 8.1752e-01, -9.9227e-02,  6.8557e-01],\n",
      "         [ 9.4609e-01, -2.2790e-01,  9.8299e-01],\n",
      "         [ 9.0975e-01, -1.9419e-01,  9.0320e-01]],\n",
      "\n",
      "        [[ 9.0515e-01, -1.9586e-01,  8.9783e-01],\n",
      "         [ 8.5779e-01, -1.4730e-01,  7.8620e-01],\n",
      "         [ 1.0213e+00, -3.0741e-01,  1.1609e+00],\n",
      "         [ 7.6421e-01, -5.0561e-02,  5.6503e-01],\n",
      "         [ 9.7382e-01, -2.5752e-01,  1.0466e+00]],\n",
      "\n",
      "        [[ 4.5753e-01,  2.7033e-01, -1.5231e-01],\n",
      "         [ 3.2947e-01,  3.9646e-01, -4.4669e-01],\n",
      "         [ 3.7271e-01,  3.5448e-01, -3.4592e-01],\n",
      "         [ 4.4334e-01,  2.8299e-01, -1.8510e-01],\n",
      "         [ 4.6438e-01,  2.6390e-01, -1.3630e-01]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.7007,  0.0666,  0.5060],\n",
      "         [ 0.7733,  0.0084,  0.6742],\n",
      "         [ 0.8013, -0.0140,  0.7389],\n",
      "         [ 0.8054, -0.0172,  0.7484],\n",
      "         [ 0.2630,  0.4171, -0.5072]],\n",
      "\n",
      "        [[ 1.0119, -0.2960,  1.1443],\n",
      "         [ 0.9550, -0.2378,  1.0102],\n",
      "         [ 0.9223, -0.2048,  0.9339],\n",
      "         [ 0.9695, -0.2512,  1.0424],\n",
      "         [ 0.9624, -0.2593,  1.0474]],\n",
      "\n",
      "        [[ 0.8745, -0.1548,  0.8135],\n",
      "         [ 0.9146, -0.1957,  0.9078],\n",
      "         [ 0.9739, -0.2549,  1.0449],\n",
      "         [ 0.9286, -0.2089,  0.9394],\n",
      "         [ 0.8629, -0.1434,  0.7867]],\n",
      "\n",
      "        [[ 0.7790, -0.0633,  0.6000],\n",
      "         [ 0.8306, -0.1133,  0.7171],\n",
      "         [ 0.8643, -0.1448,  0.7923],\n",
      "         [ 0.9661, -0.2465,  1.0276],\n",
      "         [ 0.9376, -0.2201,  0.9652]],\n",
      "\n",
      "        [[ 0.9623, -0.2503,  1.0265],\n",
      "         [ 0.9264, -0.2134,  0.9418],\n",
      "         [ 1.0441, -0.3284,  1.2110],\n",
      "         [ 0.8520, -0.1366,  0.7658],\n",
      "         [ 1.0081, -0.2905,  1.1242]],\n",
      "\n",
      "        [[ 0.4283,  0.2995, -0.2191],\n",
      "         [ 0.3255,  0.4006, -0.4551],\n",
      "         [ 0.3600,  0.3670, -0.3748],\n",
      "         [ 0.4176,  0.3091, -0.2439],\n",
      "         [ 0.4336,  0.2944, -0.2066]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.7375,  0.0372,  0.5912],\n",
      "         [ 0.7929, -0.0072,  0.7195],\n",
      "         [ 0.8142, -0.0242,  0.7687],\n",
      "         [ 0.8166, -0.0260,  0.7742],\n",
      "         [ 0.3856,  0.3195, -0.2240]],\n",
      "\n",
      "        [[ 1.0206, -0.3034,  1.1628],\n",
      "         [ 0.9772, -0.2590,  1.0606],\n",
      "         [ 0.9518, -0.2334,  1.0012],\n",
      "         [ 0.9875, -0.2684,  1.0833],\n",
      "         [ 0.9923, -0.2856,  1.1123]],\n",
      "\n",
      "        [[ 0.9141, -0.1934,  0.9038],\n",
      "         [ 0.9443, -0.2242,  0.9749],\n",
      "         [ 0.9882, -0.2680,  1.0765],\n",
      "         [ 0.9523, -0.2316,  0.9929],\n",
      "         [ 0.9029, -0.1822,  0.8777]],\n",
      "\n",
      "        [[ 0.8370, -0.1196,  0.7321],\n",
      "         [ 0.8764, -0.1576,  0.8212],\n",
      "         [ 0.8994, -0.1789,  0.8722],\n",
      "         [ 0.9788, -0.2581,  1.0556],\n",
      "         [ 0.9570, -0.2380,  1.0080]],\n",
      "\n",
      "        [[ 1.0025, -0.2882,  1.1165],\n",
      "         [ 0.9758, -0.2608,  1.0535],\n",
      "         [ 1.0593, -0.3422,  1.2442],\n",
      "         [ 0.9184, -0.2015,  0.9175],\n",
      "         [ 1.0322, -0.3136,  1.1786]],\n",
      "\n",
      "        [[ 0.4047,  0.3230, -0.2730],\n",
      "         [ 0.3222,  0.4039, -0.4619],\n",
      "         [ 0.3498,  0.3771, -0.3980],\n",
      "         [ 0.3966,  0.3303, -0.2920],\n",
      "         [ 0.4089,  0.3189, -0.2631]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.7653,  0.0150,  0.6556],\n",
      "         [ 0.8073, -0.0186,  0.7527],\n",
      "         [ 0.8234, -0.0315,  0.7899],\n",
      "         [ 0.8246, -0.0325,  0.7928],\n",
      "         [ 0.4875,  0.2376,  0.0123]],\n",
      "\n",
      "        [[ 1.0259, -0.3076,  1.1737],\n",
      "         [ 0.9929, -0.2740,  1.0961],\n",
      "         [ 0.9733, -0.2542,  1.0504],\n",
      "         [ 1.0002, -0.2806,  1.1121],\n",
      "         [ 1.0117, -0.3020,  1.1531]],\n",
      "\n",
      "        [[ 0.9426, -0.2212,  0.9690],\n",
      "         [ 0.9652, -0.2443,  1.0221],\n",
      "         [ 0.9976, -0.2766,  1.0971],\n",
      "         [ 0.9694, -0.2481,  1.0316],\n",
      "         [ 0.9324, -0.2108,  0.9448]],\n",
      "\n",
      "        [[ 0.8804, -0.1616,  0.8308],\n",
      "         [ 0.9099, -0.1900,  0.8974],\n",
      "         [ 0.9254, -0.2042,  0.9315],\n",
      "         [ 0.9866, -0.2652,  1.0727],\n",
      "         [ 0.9702, -0.2502,  1.0372]],\n",
      "\n",
      "        [[ 1.0303, -0.3142,  1.1782],\n",
      "         [ 1.0106, -0.2941,  1.1320],\n",
      "         [ 1.0693, -0.3512,  1.2659],\n",
      "         [ 0.9672, -0.2492,  1.0291],\n",
      "         [ 1.0490, -0.3297,  1.2165]],\n",
      "\n",
      "        [[ 0.3856,  0.3418, -0.3164],\n",
      "         [ 0.3196,  0.4066, -0.4675],\n",
      "         [ 0.3416,  0.3851, -0.4165],\n",
      "         [ 0.3794,  0.3475, -0.3310],\n",
      "         [ 0.3890,  0.3385, -0.3085]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.7862, -0.0017,  0.7039],\n",
      "         [ 0.8178, -0.0270,  0.7769],\n",
      "         [ 0.8299, -0.0367,  0.8050],\n",
      "         [ 0.8305, -0.0371,  0.8063],\n",
      "         [ 0.5705,  0.1710,  0.2046]],\n",
      "\n",
      "        [[ 1.0289, -0.3100,  1.1798],\n",
      "         [ 1.0040, -0.2845,  1.1211],\n",
      "         [ 0.9889, -0.2694,  1.0861],\n",
      "         [ 1.0091, -0.2891,  1.1323],\n",
      "         [ 1.0238, -0.3115,  1.1774]],\n",
      "\n",
      "        [[ 0.9631, -0.2411,  1.0157],\n",
      "         [ 0.9798, -0.2583,  1.0552],\n",
      "         [ 1.0037, -0.2821,  1.1104],\n",
      "         [ 0.9817, -0.2599,  1.0594],\n",
      "         [ 0.9539, -0.2318,  0.9939]],\n",
      "\n",
      "        [[ 0.9125, -0.1926,  0.9036],\n",
      "         [ 0.9343, -0.2135,  0.9527],\n",
      "         [ 0.9446, -0.2229,  0.9752],\n",
      "         [ 0.9913, -0.2694,  1.0831],\n",
      "         [ 0.9793, -0.2584,  1.0570]],\n",
      "\n",
      "        [[ 1.0492, -0.3318,  1.2201],\n",
      "         [ 1.0349, -0.3171,  1.1864],\n",
      "         [ 1.0759, -0.3570,  1.2799],\n",
      "         [ 1.0025, -0.2837,  1.1096],\n",
      "         [ 1.0606, -0.3408,  1.2428]],\n",
      "\n",
      "        [[ 0.3703,  0.3569, -0.3512],\n",
      "         [ 0.3175,  0.4087, -0.4720],\n",
      "         [ 0.3351,  0.3916, -0.4314],\n",
      "         [ 0.3655,  0.3613, -0.3625],\n",
      "         [ 0.3730,  0.3542, -0.3449]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8017, -0.0141,  0.7399],\n",
      "         [ 0.8254, -0.0330,  0.7946],\n",
      "         [ 0.8345, -0.0403,  0.8157],\n",
      "         [ 0.8347, -0.0404,  0.8160],\n",
      "         [ 0.6366,  0.1180,  0.3578]],\n",
      "\n",
      "        [[ 1.0305, -0.3111,  1.1828],\n",
      "         [ 1.0117, -0.2919,  1.1386],\n",
      "         [ 1.0003, -0.2804,  1.1119],\n",
      "         [ 1.0153, -0.2951,  1.1464],\n",
      "         [ 1.0309, -0.3165,  1.1908]],\n",
      "\n",
      "        [[ 0.9776, -0.2553,  1.0489],\n",
      "         [ 0.9900, -0.2680,  1.0782],\n",
      "         [ 1.0076, -0.2856,  1.1188],\n",
      "         [ 0.9906, -0.2684,  1.0793],\n",
      "         [ 0.9697, -0.2471,  1.0299]],\n",
      "\n",
      "        [[ 0.9359, -0.2152,  0.9567],\n",
      "         [ 0.9519, -0.2305,  0.9926],\n",
      "         [ 0.9586, -0.2366,  1.0072],\n",
      "         [ 0.9941, -0.2719,  1.0892],\n",
      "         [ 0.9854, -0.2640,  1.0702]],\n",
      "\n",
      "        [[ 1.0619, -0.3435,  1.2481],\n",
      "         [ 1.0515, -0.3329,  1.2237],\n",
      "         [ 1.0801, -0.3607,  1.2888],\n",
      "         [ 1.0276, -0.3082,  1.1669],\n",
      "         [ 1.0686, -0.3485,  1.2610]],\n",
      "\n",
      "        [[ 0.3581,  0.3690, -0.3791],\n",
      "         [ 0.3158,  0.4104, -0.4757],\n",
      "         [ 0.3299,  0.3967, -0.4433],\n",
      "         [ 0.3543,  0.3724, -0.3879],\n",
      "         [ 0.3602,  0.3668, -0.3741]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8133, -0.0234,  0.7666],\n",
      "         [ 0.8309, -0.0375,  0.8074],\n",
      "         [ 0.8378, -0.0429,  0.8232],\n",
      "         [ 0.8377, -0.0429,  0.8230],\n",
      "         [ 0.6882,  0.0766,  0.4773]],\n",
      "\n",
      "        [[ 1.0313, -0.3115,  1.1841],\n",
      "         [ 1.0171, -0.2970,  1.1508],\n",
      "         [ 1.0084, -0.2883,  1.1305],\n",
      "         [ 1.0196, -0.2993,  1.1563],\n",
      "         [ 1.0347, -0.3186,  1.1972]],\n",
      "\n",
      "        [[ 0.9879, -0.2654,  1.0724],\n",
      "         [ 0.9971, -0.2748,  1.0942],\n",
      "         [ 1.0100, -0.2877,  1.1240],\n",
      "         [ 0.9969, -0.2745,  1.0936],\n",
      "         [ 0.9811, -0.2583,  1.0562]],\n",
      "\n",
      "        [[ 0.9530, -0.2316,  0.9952],\n",
      "         [ 0.9646, -0.2427,  1.0213],\n",
      "         [ 0.9689, -0.2466,  1.0307],\n",
      "         [ 0.9958, -0.2733,  1.0927],\n",
      "         [ 0.9894, -0.2676,  1.0791]],\n",
      "\n",
      "        [[ 1.0704, -0.3514,  1.2668],\n",
      "         [ 1.0629, -0.3437,  1.2492],\n",
      "         [ 1.0828, -0.3630,  1.2944],\n",
      "         [ 1.0453, -0.3255,  1.2074],\n",
      "         [ 1.0742, -0.3539,  1.2735]],\n",
      "\n",
      "        [[ 0.3483,  0.3786, -0.4014],\n",
      "         [ 0.3145,  0.4117, -0.4786],\n",
      "         [ 0.3257,  0.4008, -0.4528],\n",
      "         [ 0.3453,  0.3814, -0.4084],\n",
      "         [ 0.3500,  0.3769, -0.3974]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8218, -0.0302,  0.7863],\n",
      "         [ 0.8350, -0.0407,  0.8167],\n",
      "         [ 0.8401, -0.0448,  0.8286],\n",
      "         [ 0.8399, -0.0446,  0.8281],\n",
      "         [ 0.7279,  0.0449,  0.5691]],\n",
      "\n",
      "        [[ 1.0316, -0.3115,  1.1844],\n",
      "         [ 1.0209, -0.3006,  1.1593],\n",
      "         [ 1.0143, -0.2940,  1.1440],\n",
      "         [ 1.0227, -0.3022,  1.1632],\n",
      "         [ 1.0363, -0.3190,  1.1994]],\n",
      "\n",
      "        [[ 0.9952, -0.2725,  1.0891],\n",
      "         [ 1.0020, -0.2795,  1.1052],\n",
      "         [ 1.0115, -0.2890,  1.1272],\n",
      "         [ 1.0014, -0.2789,  1.1038],\n",
      "         [ 0.9895, -0.2666,  1.0754]],\n",
      "\n",
      "        [[ 0.9653, -0.2435,  1.0231],\n",
      "         [ 0.9737, -0.2515,  1.0419],\n",
      "         [ 0.9764, -0.2539,  1.0478],\n",
      "         [ 0.9967, -0.2741,  1.0945],\n",
      "         [ 0.9921, -0.2700,  1.0849]],\n",
      "\n",
      "        [[ 1.0761, -0.3565,  1.2792],\n",
      "         [ 1.0707, -0.3510,  1.2665],\n",
      "         [ 1.0844, -0.3644,  1.2979],\n",
      "         [ 1.0578, -0.3377,  1.2359],\n",
      "         [ 1.0780, -0.3575,  1.2822]],\n",
      "\n",
      "        [[ 0.3404,  0.3863, -0.4193],\n",
      "         [ 0.3134,  0.4128, -0.4810],\n",
      "         [ 0.3224,  0.4041, -0.4604],\n",
      "         [ 0.3381,  0.3885, -0.4248],\n",
      "         [ 0.3418,  0.3850, -0.4161]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8281, -0.0352,  0.8009],\n",
      "         [ 0.8379, -0.0430,  0.8235],\n",
      "         [ 0.8417, -0.0461,  0.8324],\n",
      "         [ 0.8415, -0.0459,  0.8318],\n",
      "         [ 0.7580,  0.0208,  0.6388]],\n",
      "\n",
      "        [[ 1.0316, -0.3112,  1.1841],\n",
      "         [ 1.0235, -0.3031,  1.1652],\n",
      "         [ 1.0186, -0.2981,  1.1537],\n",
      "         [ 1.0248, -0.3042,  1.1680],\n",
      "         [ 1.0368, -0.3185,  1.1990]],\n",
      "\n",
      "        [[ 1.0003, -0.2776,  1.1009],\n",
      "         [ 1.0054, -0.2827,  1.1129],\n",
      "         [ 1.0124, -0.2897,  1.1290],\n",
      "         [ 1.0047, -0.2820,  1.1111],\n",
      "         [ 0.9956, -0.2726,  1.0895]],\n",
      "\n",
      "        [[ 0.9741, -0.2520,  1.0431],\n",
      "         [ 0.9802, -0.2578,  1.0567],\n",
      "         [ 0.9819, -0.2592,  1.0602],\n",
      "         [ 0.9971, -0.2744,  1.0954],\n",
      "         [ 0.9939, -0.2716,  1.0886]],\n",
      "\n",
      "        [[ 1.0798, -0.3599,  1.2873],\n",
      "         [ 1.0759, -0.3560,  1.2782],\n",
      "         [ 1.0855, -0.3652,  1.2999],\n",
      "         [ 1.0665, -0.3462,  1.2558],\n",
      "         [ 1.0806, -0.3601,  1.2882]],\n",
      "\n",
      "        [[ 0.3341,  0.3925, -0.4336],\n",
      "         [ 0.3125,  0.4137, -0.4829],\n",
      "         [ 0.3197,  0.4067, -0.4665],\n",
      "         [ 0.3323,  0.3942, -0.4379],\n",
      "         [ 0.3352,  0.3914, -0.4311]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8327, -0.0389,  0.8116],\n",
      "         [ 0.8400, -0.0447,  0.8284],\n",
      "         [ 0.8429, -0.0470,  0.8350],\n",
      "         [ 0.8426, -0.0468,  0.8344],\n",
      "         [ 0.7807,  0.0027,  0.6912]],\n",
      "\n",
      "        [[ 1.0314, -0.3109,  1.1835],\n",
      "         [ 1.0254, -0.3048,  1.1694],\n",
      "         [ 1.0216, -0.3010,  1.1606],\n",
      "         [ 1.0263, -0.3056,  1.1713],\n",
      "         [ 1.0365, -0.3175,  1.1974]],\n",
      "\n",
      "        [[ 1.0040, -0.2811,  1.1093],\n",
      "         [ 1.0077, -0.2850,  1.1181],\n",
      "         [ 1.0129, -0.2901,  1.1300],\n",
      "         [ 1.0070, -0.2842,  1.1163],\n",
      "         [ 1.0000, -0.2770,  1.0998]],\n",
      "\n",
      "        [[ 0.9805, -0.2581,  1.0575],\n",
      "         [ 0.9848, -0.2623,  1.0672],\n",
      "         [ 0.9858, -0.2631,  1.0693],\n",
      "         [ 0.9973, -0.2745,  1.0958],\n",
      "         [ 0.9950, -0.2725,  1.0910]],\n",
      "\n",
      "        [[ 1.0823, -0.3621,  1.2926],\n",
      "         [ 1.0795, -0.3593,  1.2861],\n",
      "         [ 1.0861, -0.3657,  1.3011],\n",
      "         [ 1.0726, -0.3521,  1.2697],\n",
      "         [ 1.0824, -0.3618,  1.2923]],\n",
      "\n",
      "        [[ 0.3291,  0.3974, -0.4451],\n",
      "         [ 0.3118,  0.4144, -0.4845],\n",
      "         [ 0.3176,  0.4088, -0.4713],\n",
      "         [ 0.3276,  0.3988, -0.4485],\n",
      "         [ 0.3300,  0.3965, -0.4430]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8361, -0.0416,  0.8195],\n",
      "         [ 0.8415, -0.0459,  0.8319],\n",
      "         [ 0.8437, -0.0476,  0.8369],\n",
      "         [ 0.8434, -0.0474,  0.8363],\n",
      "         [ 0.7976, -0.0108,  0.7304]],\n",
      "\n",
      "        [[ 1.0312, -0.3106,  1.1828],\n",
      "         [ 1.0266, -0.3060,  1.1722],\n",
      "         [ 1.0238, -0.3032,  1.1656],\n",
      "         [ 1.0273, -0.3066,  1.1736],\n",
      "         [ 1.0358, -0.3163,  1.1951]],\n",
      "\n",
      "        [[ 1.0066, -0.2837,  1.1152],\n",
      "         [ 1.0093, -0.2865,  1.1217],\n",
      "         [ 1.0131, -0.2903,  1.1305],\n",
      "         [ 1.0086, -0.2858,  1.1201],\n",
      "         [ 1.0033, -0.2803,  1.1074]],\n",
      "\n",
      "        [[ 0.9850, -0.2625,  1.0678],\n",
      "         [ 0.9882, -0.2655,  1.0748],\n",
      "         [ 0.9887, -0.2659,  1.0759],\n",
      "         [ 0.9973, -0.2745,  1.0958],\n",
      "         [ 0.9958, -0.2732,  1.0925]],\n",
      "\n",
      "        [[ 1.0838, -0.3635,  1.2960],\n",
      "         [ 1.0819, -0.3615,  1.2914],\n",
      "         [ 1.0864, -0.3660,  1.3018],\n",
      "         [ 1.0768, -0.3563,  1.2794],\n",
      "         [ 1.0837, -0.3630,  1.2951]],\n",
      "\n",
      "        [[ 0.3251,  0.4014, -0.4542],\n",
      "         [ 0.3113,  0.4149, -0.4857],\n",
      "         [ 0.3159,  0.4104, -0.4752],\n",
      "         [ 0.3239,  0.4025, -0.4569],\n",
      "         [ 0.3258,  0.4007, -0.4526]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8386, -0.0436,  0.8252],\n",
      "         [ 0.8426, -0.0468,  0.8345],\n",
      "         [ 0.8443, -0.0481,  0.8382],\n",
      "         [ 0.8440, -0.0479,  0.8377],\n",
      "         [ 0.8102, -0.0209,  0.7595]],\n",
      "\n",
      "        [[ 1.0309, -0.3103,  1.1822],\n",
      "         [ 1.0275, -0.3068,  1.1742],\n",
      "         [ 1.0254, -0.3047,  1.1692],\n",
      "         [ 1.0280, -0.3072,  1.1752],\n",
      "         [ 1.0350, -0.3151,  1.1927]],\n",
      "\n",
      "        [[ 1.0084, -0.2854,  1.1194],\n",
      "         [ 1.0104, -0.2876,  1.1242],\n",
      "         [ 1.0132, -0.2904,  1.1307],\n",
      "         [ 1.0098, -0.2869,  1.1228],\n",
      "         [ 1.0058, -0.2827,  1.1130]],\n",
      "\n",
      "        [[ 0.9883, -0.2657,  1.0752],\n",
      "         [ 0.9905, -0.2678,  1.0802],\n",
      "         [ 0.9908, -0.2680,  1.0808],\n",
      "         [ 0.9973, -0.2744,  1.0956],\n",
      "         [ 0.9962, -0.2735,  1.0935]],\n",
      "\n",
      "        [[ 1.0849, -0.3644,  1.2983],\n",
      "         [ 1.0835, -0.3630,  1.2949],\n",
      "         [ 1.0866, -0.3661,  1.3021],\n",
      "         [ 1.0798, -0.3592,  1.2862],\n",
      "         [ 1.0846, -0.3639,  1.2971]],\n",
      "\n",
      "        [[ 0.3219,  0.4045, -0.4615],\n",
      "         [ 0.3109,  0.4153, -0.4867],\n",
      "         [ 0.3145,  0.4118, -0.4783],\n",
      "         [ 0.3210,  0.4054, -0.4637],\n",
      "         [ 0.3224,  0.4040, -0.4602]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8405, -0.0451,  0.8295],\n",
      "         [ 0.8435, -0.0474,  0.8364],\n",
      "         [ 0.8447, -0.0484,  0.8391],\n",
      "         [ 0.8445, -0.0482,  0.8387],\n",
      "         [ 0.8195, -0.0283,  0.7810]],\n",
      "\n",
      "        [[ 1.0307, -0.3100,  1.1815],\n",
      "         [ 1.0281, -0.3074,  1.1756],\n",
      "         [ 1.0265, -0.3058,  1.1718],\n",
      "         [ 1.0285, -0.3077,  1.1762],\n",
      "         [ 1.0342, -0.3140,  1.1904]],\n",
      "\n",
      "        [[ 1.0097, -0.2867,  1.1223],\n",
      "         [ 1.0112, -0.2883,  1.1259],\n",
      "         [ 1.0133, -0.2904,  1.1307],\n",
      "         [ 1.0106, -0.2877,  1.1247],\n",
      "         [ 1.0075, -0.2845,  1.1172]],\n",
      "\n",
      "        [[ 0.9906, -0.2679,  1.0805],\n",
      "         [ 0.9922, -0.2694,  1.0841],\n",
      "         [ 0.9924, -0.2695,  1.0843],\n",
      "         [ 0.9972, -0.2743,  1.0954],\n",
      "         [ 0.9965, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0855, -0.3650,  1.2997],\n",
      "         [ 1.0845, -0.3640,  1.2973],\n",
      "         [ 1.0867, -0.3661,  1.3023],\n",
      "         [ 1.0818, -0.3612,  1.2909],\n",
      "         [ 1.0852, -0.3645,  1.2985]],\n",
      "\n",
      "        [[ 0.3193,  0.4070, -0.4674],\n",
      "         [ 0.3105,  0.4157, -0.4875],\n",
      "         [ 0.3134,  0.4128, -0.4808],\n",
      "         [ 0.3186,  0.4077, -0.4691],\n",
      "         [ 0.3198,  0.4066, -0.4663]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8418, -0.0462,  0.8326],\n",
      "         [ 0.8440, -0.0479,  0.8377],\n",
      "         [ 0.8449, -0.0486,  0.8398],\n",
      "         [ 0.8448, -0.0485,  0.8394],\n",
      "         [ 0.8264, -0.0338,  0.7969]],\n",
      "\n",
      "        [[ 1.0305, -0.3097,  1.1810],\n",
      "         [ 1.0286, -0.3078,  1.1765],\n",
      "         [ 1.0274, -0.3066,  1.1737],\n",
      "         [ 1.0288, -0.3080,  1.1770],\n",
      "         [ 1.0334, -0.3131,  1.1883]],\n",
      "\n",
      "        [[ 1.0106, -0.2876,  1.1244],\n",
      "         [ 1.0117, -0.2888,  1.1271],\n",
      "         [ 1.0132, -0.2903,  1.1306],\n",
      "         [ 1.0113, -0.2883,  1.1260],\n",
      "         [ 1.0089, -0.2858,  1.1203]],\n",
      "\n",
      "        [[ 0.9923, -0.2695,  1.0843],\n",
      "         [ 0.9935, -0.2706,  1.0868],\n",
      "         [ 0.9935, -0.2706,  1.0869],\n",
      "         [ 0.9971, -0.2742,  1.0952],\n",
      "         [ 0.9966, -0.2738,  1.0943]],\n",
      "\n",
      "        [[ 1.0860, -0.3654,  1.3005],\n",
      "         [ 1.0852, -0.3646,  1.2988],\n",
      "         [ 1.0868, -0.3661,  1.3023],\n",
      "         [ 1.0833, -0.3626,  1.2942],\n",
      "         [ 1.0856, -0.3649,  1.2995]],\n",
      "\n",
      "        [[ 0.3173,  0.4091, -0.4720],\n",
      "         [ 0.3102,  0.4160, -0.4881],\n",
      "         [ 0.3126,  0.4137, -0.4828],\n",
      "         [ 0.3167,  0.4096, -0.4734],\n",
      "         [ 0.3176,  0.4087, -0.4712]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8428, -0.0469,  0.8349],\n",
      "         [ 0.8445, -0.0482,  0.8387],\n",
      "         [ 0.8451, -0.0488,  0.8403],\n",
      "         [ 0.8450, -0.0487,  0.8399],\n",
      "         [ 0.8315, -0.0379,  0.8087]],\n",
      "\n",
      "        [[ 1.0303, -0.3095,  1.1805],\n",
      "         [ 1.0289, -0.3081,  1.1772],\n",
      "         [ 1.0279, -0.3072,  1.1751],\n",
      "         [ 1.0290, -0.3082,  1.1775],\n",
      "         [ 1.0327, -0.3122,  1.1865]],\n",
      "\n",
      "        [[ 1.0112, -0.2883,  1.1259],\n",
      "         [ 1.0121, -0.2891,  1.1279],\n",
      "         [ 1.0132, -0.2902,  1.1305],\n",
      "         [ 1.0117, -0.2887,  1.1270],\n",
      "         [ 1.0098, -0.2868,  1.1226]],\n",
      "\n",
      "        [[ 0.9935, -0.2707,  1.0870],\n",
      "         [ 0.9943, -0.2715,  1.0888],\n",
      "         [ 0.9943, -0.2714,  1.0887],\n",
      "         [ 0.9970, -0.2741,  1.0950],\n",
      "         [ 0.9967, -0.2739,  1.0944]],\n",
      "\n",
      "        [[ 1.0862, -0.3656,  1.3011],\n",
      "         [ 1.0857, -0.3651,  1.2999],\n",
      "         [ 1.0868, -0.3661,  1.3023],\n",
      "         [ 1.0843, -0.3636,  1.2965],\n",
      "         [ 1.0859, -0.3652,  1.3001]],\n",
      "\n",
      "        [[ 0.3156,  0.4107, -0.4758],\n",
      "         [ 0.3100,  0.4162, -0.4886],\n",
      "         [ 0.3119,  0.4143, -0.4844],\n",
      "         [ 0.3152,  0.4111, -0.4769],\n",
      "         [ 0.3159,  0.4104, -0.4751]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8436, -0.0475,  0.8366],\n",
      "         [ 0.8448, -0.0485,  0.8394],\n",
      "         [ 0.8453, -0.0489,  0.8406],\n",
      "         [ 0.8452, -0.0488,  0.8403],\n",
      "         [ 0.8352, -0.0409,  0.8173]],\n",
      "\n",
      "        [[ 1.0301, -0.3094,  1.1801],\n",
      "         [ 1.0291, -0.3083,  1.1776],\n",
      "         [ 1.0284, -0.3076,  1.1760],\n",
      "         [ 1.0292, -0.3084,  1.1779],\n",
      "         [ 1.0321, -0.3115,  1.1850]],\n",
      "\n",
      "        [[ 1.0117, -0.2887,  1.1270],\n",
      "         [ 1.0123, -0.2894,  1.1285],\n",
      "         [ 1.0131, -0.2902,  1.1304],\n",
      "         [ 1.0120, -0.2890,  1.1277],\n",
      "         [ 1.0106, -0.2876,  1.1243]],\n",
      "\n",
      "        [[ 0.9944, -0.2715,  1.0890],\n",
      "         [ 0.9950, -0.2721,  1.0903],\n",
      "         [ 0.9949, -0.2720,  1.0901],\n",
      "         [ 0.9969, -0.2740,  1.0948],\n",
      "         [ 0.9968, -0.2739,  1.0944]],\n",
      "\n",
      "        [[ 1.0864, -0.3657,  1.3014],\n",
      "         [ 1.0860, -0.3654,  1.3005],\n",
      "         [ 1.0868, -0.3661,  1.3022],\n",
      "         [ 1.0850, -0.3643,  1.2981],\n",
      "         [ 1.0861, -0.3654,  1.3006]],\n",
      "\n",
      "        [[ 0.3143,  0.4119, -0.4788],\n",
      "         [ 0.3098,  0.4164, -0.4890],\n",
      "         [ 0.3113,  0.4149, -0.4856],\n",
      "         [ 0.3139,  0.4123, -0.4796],\n",
      "         [ 0.3146,  0.4117, -0.4782]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8441, -0.0480,  0.8379],\n",
      "         [ 0.8450, -0.0487,  0.8399],\n",
      "         [ 0.8454, -0.0490,  0.8408],\n",
      "         [ 0.8453, -0.0489,  0.8406],\n",
      "         [ 0.8380, -0.0431,  0.8237]],\n",
      "\n",
      "        [[ 1.0300, -0.3092,  1.1798],\n",
      "         [ 1.0292, -0.3084,  1.1779],\n",
      "         [ 1.0287, -0.3079,  1.1767],\n",
      "         [ 1.0293, -0.3085,  1.1781],\n",
      "         [ 1.0316, -0.3109,  1.1837]],\n",
      "\n",
      "        [[ 1.0120, -0.2890,  1.1277],\n",
      "         [ 1.0125, -0.2895,  1.1288],\n",
      "         [ 1.0131, -0.2901,  1.1303],\n",
      "         [ 1.0122, -0.2893,  1.1283],\n",
      "         [ 1.0111, -0.2881,  1.1256]],\n",
      "\n",
      "        [[ 0.9950, -0.2721,  1.0904],\n",
      "         [ 0.9954, -0.2725,  1.0913],\n",
      "         [ 0.9954, -0.2724,  1.0911],\n",
      "         [ 0.9969, -0.2740,  1.0946],\n",
      "         [ 0.9968, -0.2739,  1.0944]],\n",
      "\n",
      "        [[ 1.0865, -0.3658,  1.3016],\n",
      "         [ 1.0862, -0.3655,  1.3010],\n",
      "         [ 1.0867, -0.3661,  1.3022],\n",
      "         [ 1.0855, -0.3648,  1.2992],\n",
      "         [ 1.0862, -0.3655,  1.3009]],\n",
      "\n",
      "        [[ 0.3133,  0.4130, -0.4812],\n",
      "         [ 0.3097,  0.4165, -0.4894],\n",
      "         [ 0.3109,  0.4153, -0.4866],\n",
      "         [ 0.3130,  0.4133, -0.4818],\n",
      "         [ 0.3135,  0.4128, -0.4807]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8445, -0.0483,  0.8388],\n",
      "         [ 0.8452, -0.0488,  0.8403],\n",
      "         [ 0.8454, -0.0490,  0.8410],\n",
      "         [ 0.8454, -0.0490,  0.8408],\n",
      "         [ 0.8400, -0.0447,  0.8283]],\n",
      "\n",
      "        [[ 1.0299, -0.3091,  1.1795],\n",
      "         [ 1.0293, -0.3085,  1.1781],\n",
      "         [ 1.0289, -0.3081,  1.1772],\n",
      "         [ 1.0294, -0.3085,  1.1783],\n",
      "         [ 1.0312, -0.3105,  1.1826]],\n",
      "\n",
      "        [[ 1.0122, -0.2893,  1.1283],\n",
      "         [ 1.0126, -0.2896,  1.1291],\n",
      "         [ 1.0130, -0.2901,  1.1301],\n",
      "         [ 1.0124, -0.2894,  1.1286],\n",
      "         [ 1.0115, -0.2885,  1.1266]],\n",
      "\n",
      "        [[ 0.9955, -0.2726,  1.0914],\n",
      "         [ 0.9957, -0.2728,  1.0920],\n",
      "         [ 0.9957, -0.2728,  1.0919],\n",
      "         [ 0.9968, -0.2739,  1.0945],\n",
      "         [ 0.9968, -0.2739,  1.0944]],\n",
      "\n",
      "        [[ 1.0865, -0.3659,  1.3017],\n",
      "         [ 1.0864, -0.3657,  1.3013],\n",
      "         [ 1.0867, -0.3660,  1.3021],\n",
      "         [ 1.0858, -0.3651,  1.3000],\n",
      "         [ 1.0863, -0.3656,  1.3012]],\n",
      "\n",
      "        [[ 0.3124,  0.4138, -0.4831],\n",
      "         [ 0.3096,  0.4166, -0.4896],\n",
      "         [ 0.3105,  0.4157, -0.4874],\n",
      "         [ 0.3122,  0.4140, -0.4836],\n",
      "         [ 0.3126,  0.4136, -0.4827]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8448, -0.0485,  0.8394],\n",
      "         [ 0.8453, -0.0489,  0.8406],\n",
      "         [ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8454, -0.0490,  0.8409],\n",
      "         [ 0.8415, -0.0459,  0.8318]],\n",
      "\n",
      "        [[ 1.0298, -0.3090,  1.1793],\n",
      "         [ 1.0294, -0.3085,  1.1783],\n",
      "         [ 1.0291, -0.3083,  1.1776],\n",
      "         [ 1.0294, -0.3086,  1.1784],\n",
      "         [ 1.0308, -0.3101,  1.1818]],\n",
      "\n",
      "        [[ 1.0124, -0.2894,  1.1286],\n",
      "         [ 1.0127, -0.2897,  1.1293],\n",
      "         [ 1.0130, -0.2900,  1.1300],\n",
      "         [ 1.0125, -0.2895,  1.1289],\n",
      "         [ 1.0119, -0.2888,  1.1273]],\n",
      "\n",
      "        [[ 0.9958, -0.2729,  1.0921],\n",
      "         [ 0.9960, -0.2731,  1.0925],\n",
      "         [ 0.9959, -0.2730,  1.0924],\n",
      "         [ 0.9968, -0.2738,  1.0944],\n",
      "         [ 0.9967, -0.2738,  1.0943]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0864, -0.3657,  1.3015],\n",
      "         [ 1.0867, -0.3660,  1.3020],\n",
      "         [ 1.0860, -0.3653,  1.3005],\n",
      "         [ 1.0864, -0.3657,  1.3013]],\n",
      "\n",
      "        [[ 0.3118,  0.4144, -0.4846],\n",
      "         [ 0.3095,  0.4167, -0.4898],\n",
      "         [ 0.3102,  0.4159, -0.4881],\n",
      "         [ 0.3116,  0.4146, -0.4850],\n",
      "         [ 0.3119,  0.4143, -0.4843]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8450, -0.0487,  0.8399],\n",
      "         [ 0.8454, -0.0490,  0.8408],\n",
      "         [ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8455, -0.0490,  0.8410],\n",
      "         [ 0.8426, -0.0467,  0.8343]],\n",
      "\n",
      "        [[ 1.0297, -0.3089,  1.1792],\n",
      "         [ 1.0294, -0.3086,  1.1784],\n",
      "         [ 1.0292, -0.3084,  1.1779],\n",
      "         [ 1.0294, -0.3086,  1.1785],\n",
      "         [ 1.0305, -0.3098,  1.1811]],\n",
      "\n",
      "        [[ 1.0125, -0.2895,  1.1289],\n",
      "         [ 1.0127, -0.2897,  1.1294],\n",
      "         [ 1.0130, -0.2900,  1.1300],\n",
      "         [ 1.0126, -0.2896,  1.1291],\n",
      "         [ 1.0121, -0.2891,  1.1279]],\n",
      "\n",
      "        [[ 0.9960, -0.2731,  1.0926],\n",
      "         [ 0.9961, -0.2732,  1.0929],\n",
      "         [ 0.9961, -0.2732,  1.0928],\n",
      "         [ 0.9967, -0.2738,  1.0943],\n",
      "         [ 0.9967, -0.2738,  1.0943]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0865, -0.3658,  1.3016],\n",
      "         [ 1.0867, -0.3660,  1.3020],\n",
      "         [ 1.0862, -0.3655,  1.3009],\n",
      "         [ 1.0865, -0.3657,  1.3015]],\n",
      "\n",
      "        [[ 0.3112,  0.4150, -0.4858],\n",
      "         [ 0.3094,  0.4168, -0.4900],\n",
      "         [ 0.3100,  0.4162, -0.4886],\n",
      "         [ 0.3111,  0.4151, -0.4862],\n",
      "         [ 0.3113,  0.4149, -0.4856]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8452, -0.0488,  0.8403],\n",
      "         [ 0.8454, -0.0490,  0.8409],\n",
      "         [ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8434, -0.0474,  0.8361]],\n",
      "\n",
      "        [[ 1.0297, -0.3089,  1.1790],\n",
      "         [ 1.0294, -0.3086,  1.1784],\n",
      "         [ 1.0293, -0.3085,  1.1781],\n",
      "         [ 1.0295, -0.3086,  1.1785],\n",
      "         [ 1.0303, -0.3095,  1.1805]],\n",
      "\n",
      "        [[ 1.0126, -0.2896,  1.1291],\n",
      "         [ 1.0128, -0.2898,  1.1294],\n",
      "         [ 1.0129, -0.2900,  1.1299],\n",
      "         [ 1.0127, -0.2897,  1.1292],\n",
      "         [ 1.0123, -0.2893,  1.1283]],\n",
      "\n",
      "        [[ 0.9962, -0.2732,  1.0930],\n",
      "         [ 0.9963, -0.2733,  1.0932],\n",
      "         [ 0.9962, -0.2733,  1.0931],\n",
      "         [ 0.9967, -0.2738,  1.0942],\n",
      "         [ 0.9967, -0.2738,  1.0942]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0865, -0.3658,  1.3017],\n",
      "         [ 1.0867, -0.3660,  1.3020],\n",
      "         [ 1.0863, -0.3656,  1.3012],\n",
      "         [ 1.0865, -0.3658,  1.3015]],\n",
      "\n",
      "        [[ 0.3108,  0.4154, -0.4868],\n",
      "         [ 0.3093,  0.4168, -0.4901],\n",
      "         [ 0.3098,  0.4163, -0.4890],\n",
      "         [ 0.3107,  0.4155, -0.4871],\n",
      "         [ 0.3109,  0.4153, -0.4866]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8453, -0.0489,  0.8406],\n",
      "         [ 0.8455, -0.0490,  0.8410],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8439, -0.0478,  0.8375]],\n",
      "\n",
      "        [[ 1.0296, -0.3088,  1.1789],\n",
      "         [ 1.0294, -0.3086,  1.1785],\n",
      "         [ 1.0293, -0.3085,  1.1782],\n",
      "         [ 1.0295, -0.3087,  1.1785],\n",
      "         [ 1.0301, -0.3093,  1.1801]],\n",
      "\n",
      "        [[ 1.0127, -0.2897,  1.1292],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0129, -0.2899,  1.1298],\n",
      "         [ 1.0127, -0.2897,  1.1293],\n",
      "         [ 1.0124, -0.2894,  1.1286]],\n",
      "\n",
      "        [[ 0.9963, -0.2734,  1.0932],\n",
      "         [ 0.9964, -0.2734,  1.0934],\n",
      "         [ 0.9963, -0.2734,  1.0933],\n",
      "         [ 0.9967, -0.2737,  1.0941],\n",
      "         [ 0.9967, -0.2738,  1.0942]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3658,  1.3017],\n",
      "         [ 1.0867, -0.3659,  1.3019],\n",
      "         [ 1.0864, -0.3657,  1.3013],\n",
      "         [ 1.0865, -0.3658,  1.3016]],\n",
      "\n",
      "        [[ 0.3105,  0.4157, -0.4876],\n",
      "         [ 0.3093,  0.4169, -0.4902],\n",
      "         [ 0.3097,  0.4165, -0.4893],\n",
      "         [ 0.3104,  0.4158, -0.4878],\n",
      "         [ 0.3105,  0.4157, -0.4874]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8454, -0.0490,  0.8408],\n",
      "         [ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8444, -0.0482,  0.8385]],\n",
      "\n",
      "        [[ 1.0296, -0.3088,  1.1789],\n",
      "         [ 1.0295, -0.3086,  1.1785],\n",
      "         [ 1.0294, -0.3086,  1.1783],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0300, -0.3092,  1.1798]],\n",
      "\n",
      "        [[ 1.0127, -0.2897,  1.1293],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0129, -0.2899,  1.1298],\n",
      "         [ 1.0127, -0.2898,  1.1294],\n",
      "         [ 1.0125, -0.2895,  1.1288]],\n",
      "\n",
      "        [[ 0.9964, -0.2734,  1.0934],\n",
      "         [ 0.9964, -0.2735,  1.0935],\n",
      "         [ 0.9964, -0.2735,  1.0935],\n",
      "         [ 0.9966, -0.2737,  1.0941],\n",
      "         [ 0.9967, -0.2737,  1.0941]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3017],\n",
      "         [ 1.0866, -0.3659,  1.3019],\n",
      "         [ 1.0865, -0.3657,  1.3015],\n",
      "         [ 1.0865, -0.3658,  1.3016]],\n",
      "\n",
      "        [[ 0.3102,  0.4160, -0.4882],\n",
      "         [ 0.3093,  0.4169, -0.4903],\n",
      "         [ 0.3096,  0.4166, -0.4896],\n",
      "         [ 0.3101,  0.4161, -0.4884],\n",
      "         [ 0.3102,  0.4159, -0.4881]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8454, -0.0490,  0.8409],\n",
      "         [ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8447, -0.0484,  0.8392]],\n",
      "\n",
      "        [[ 1.0296, -0.3088,  1.1788],\n",
      "         [ 1.0295, -0.3087,  1.1785],\n",
      "         [ 1.0294, -0.3086,  1.1784],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0299, -0.3091,  1.1795]],\n",
      "\n",
      "        [[ 1.0127, -0.2898,  1.1294],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0129, -0.2899,  1.1297],\n",
      "         [ 1.0128, -0.2898,  1.1294],\n",
      "         [ 1.0126, -0.2896,  1.1290]],\n",
      "\n",
      "        [[ 0.9964, -0.2735,  1.0936],\n",
      "         [ 0.9965, -0.2735,  1.0937],\n",
      "         [ 0.9964, -0.2735,  1.0936],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0941]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3019],\n",
      "         [ 1.0865, -0.3658,  1.3016],\n",
      "         [ 1.0866, -0.3658,  1.3017]],\n",
      "\n",
      "        [[ 0.3100,  0.4162, -0.4887],\n",
      "         [ 0.3092,  0.4169, -0.4904],\n",
      "         [ 0.3095,  0.4167, -0.4898],\n",
      "         [ 0.3099,  0.4163, -0.4888],\n",
      "         [ 0.3100,  0.4162, -0.4886]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8455, -0.0490,  0.8410],\n",
      "         [ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8449, -0.0486,  0.8398]],\n",
      "\n",
      "        [[ 1.0296, -0.3087,  1.1787],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0294, -0.3086,  1.1784],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0298, -0.3090,  1.1793]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0129, -0.2899,  1.1297],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0126, -0.2896,  1.1292]],\n",
      "\n",
      "        [[ 0.9965, -0.2735,  1.0937],\n",
      "         [ 0.9965, -0.2736,  1.0937],\n",
      "         [ 0.9965, -0.2735,  1.0937],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0941]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3019],\n",
      "         [ 1.0865, -0.3658,  1.3016],\n",
      "         [ 1.0866, -0.3658,  1.3017]],\n",
      "\n",
      "        [[ 0.3098,  0.4164, -0.4891],\n",
      "         [ 0.3092,  0.4170, -0.4904],\n",
      "         [ 0.3094,  0.4168, -0.4900],\n",
      "         [ 0.3098,  0.4164, -0.4892],\n",
      "         [ 0.3098,  0.4163, -0.4890]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8451, -0.0488,  0.8402]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1787],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0294, -0.3086,  1.1785],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0297, -0.3089,  1.1791]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0129, -0.2899,  1.1297],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0127, -0.2897,  1.1293]],\n",
      "\n",
      "        [[ 0.9965, -0.2736,  1.0937],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9965, -0.2736,  1.0937],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0865, -0.3658,  1.3017],\n",
      "         [ 1.0866, -0.3658,  1.3017]],\n",
      "\n",
      "        [[ 0.3097,  0.4165, -0.4894],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3093,  0.4168, -0.4901],\n",
      "         [ 0.3096,  0.4165, -0.4895],\n",
      "         [ 0.3097,  0.4165, -0.4893]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8455, -0.0491,  0.8411],\n",
      "         [ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8452, -0.0489,  0.8405]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1787],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3086,  1.1785],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0297, -0.3089,  1.1790]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0129, -0.2899,  1.1297],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0127, -0.2897,  1.1293]],\n",
      "\n",
      "        [[ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3658,  1.3017],\n",
      "         [ 1.0866, -0.3659,  1.3017]],\n",
      "\n",
      "        [[ 0.3096,  0.4166, -0.4896],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3093,  0.4169, -0.4902],\n",
      "         [ 0.3095,  0.4166, -0.4897],\n",
      "         [ 0.3096,  0.4166, -0.4896]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8455, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8453, -0.0489,  0.8407]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1787],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3086,  1.1785],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0296, -0.3088,  1.1789]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2899,  1.1297],\n",
      "         [ 1.0128, -0.2898,  1.1295],\n",
      "         [ 1.0127, -0.2898,  1.1294]],\n",
      "\n",
      "        [[ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3017],\n",
      "         [ 1.0866, -0.3659,  1.3017]],\n",
      "\n",
      "        [[ 0.3095,  0.4167, -0.4898],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3093,  0.4169, -0.4903],\n",
      "         [ 0.3094,  0.4167, -0.4899],\n",
      "         [ 0.3095,  0.4167, -0.4898]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8454, -0.0490,  0.8409]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1785],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0296, -0.3088,  1.1788]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2899,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1294]],\n",
      "\n",
      "        [[ 0.9965, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9965, -0.2736,  1.0938],\n",
      "         [ 0.9966, -0.2737,  1.0940],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3017],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3094,  0.4168, -0.4900],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4169, -0.4904],\n",
      "         [ 0.3094,  0.4168, -0.4901],\n",
      "         [ 0.3094,  0.4168, -0.4900]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8412],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8454, -0.0490,  0.8410]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0296, -0.3088,  1.1788]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2899,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1295]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3093,  0.4168, -0.4901],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4904],\n",
      "         [ 0.3093,  0.4168, -0.4902],\n",
      "         [ 0.3093,  0.4168, -0.4901]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8455, -0.0491,  0.8411]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0296, -0.3087,  1.1787]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2899,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1295]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3093,  0.4169, -0.4902],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3093,  0.4169, -0.4903],\n",
      "         [ 0.3093,  0.4169, -0.4902]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8455, -0.0491,  0.8411]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1787]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1295]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0940]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3093,  0.4169, -0.4903],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3092,  0.4169, -0.4903],\n",
      "         [ 0.3093,  0.4169, -0.4903]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8455, -0.0491,  0.8412]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1787]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3092,  0.4169, -0.4904],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3092,  0.4169, -0.4904],\n",
      "         [ 0.3092,  0.4169, -0.4904]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8455, -0.0491,  0.8412]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3092,  0.4170, -0.4904],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3092,  0.4170, -0.4904]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8412]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3092,  0.4170, -0.4905]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8412]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3092,  0.4170, -0.4905]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3092,  0.4170, -0.4905],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4906],\n",
      "         [ 0.3092,  0.4170, -0.4905]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4906],\n",
      "         [ 0.3091,  0.4170, -0.4906]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4170, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4907],\n",
      "         [ 0.3091,  0.4170, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n",
      "act tensor([[[ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413],\n",
      "         [ 0.8456, -0.0491,  0.8413]],\n",
      "\n",
      "        [[ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786],\n",
      "         [ 1.0295, -0.3087,  1.1786]],\n",
      "\n",
      "        [[ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296],\n",
      "         [ 1.0128, -0.2898,  1.1296]],\n",
      "\n",
      "        [[ 0.9966, -0.2737,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2736,  1.0939],\n",
      "         [ 0.9966, -0.2737,  1.0939]],\n",
      "\n",
      "        [[ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018],\n",
      "         [ 1.0866, -0.3659,  1.3018]],\n",
      "\n",
      "        [[ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907],\n",
      "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8456, -0.0491,  0.8413],\n",
       "         [ 0.8456, -0.0491,  0.8413],\n",
       "         [ 0.8456, -0.0491,  0.8413],\n",
       "         [ 0.8456, -0.0491,  0.8413],\n",
       "         [ 0.8456, -0.0491,  0.8413]],\n",
       "\n",
       "        [[ 1.0295, -0.3087,  1.1786],\n",
       "         [ 1.0295, -0.3087,  1.1786],\n",
       "         [ 1.0295, -0.3087,  1.1786],\n",
       "         [ 1.0295, -0.3087,  1.1786],\n",
       "         [ 1.0295, -0.3087,  1.1786]],\n",
       "\n",
       "        [[ 1.0128, -0.2898,  1.1296],\n",
       "         [ 1.0128, -0.2898,  1.1296],\n",
       "         [ 1.0128, -0.2898,  1.1296],\n",
       "         [ 1.0128, -0.2898,  1.1296],\n",
       "         [ 1.0128, -0.2898,  1.1296]],\n",
       "\n",
       "        [[ 0.9966, -0.2737,  1.0939],\n",
       "         [ 0.9966, -0.2736,  1.0939],\n",
       "         [ 0.9966, -0.2736,  1.0939],\n",
       "         [ 0.9966, -0.2736,  1.0939],\n",
       "         [ 0.9966, -0.2737,  1.0939]],\n",
       "\n",
       "        [[ 1.0866, -0.3659,  1.3018],\n",
       "         [ 1.0866, -0.3659,  1.3018],\n",
       "         [ 1.0866, -0.3659,  1.3018],\n",
       "         [ 1.0866, -0.3659,  1.3018],\n",
       "         [ 1.0866, -0.3659,  1.3018]],\n",
       "\n",
       "        [[ 0.3091,  0.4171, -0.4907],\n",
       "         [ 0.3091,  0.4171, -0.4907],\n",
       "         [ 0.3091,  0.4171, -0.4907],\n",
       "         [ 0.3091,  0.4171, -0.4907],\n",
       "         [ 0.3091,  0.4171, -0.4907]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_Dyna = Dynamics(STATELEN + ACTLEN, STATELEN, STATELEN)\n",
    "my_reward = reward(STATELEN, STATELEN , ACTLEN**2 + ACTLEN + 1)\n",
    "TIME_STEP = 6\n",
    "BATCH_SIZE = 5\n",
    "myilqr = ilqr(TIME_STEP, my_Dyna, my_reward, STATELEN, ACTLEN, BATCH_SIZE)\n",
    "action = torch.rand((TIME_STEP, BATCH_SIZE, ACTLEN))\n",
    "state = torch.zeros((TIME_STEP, BATCH_SIZE, STATELEN))\n",
    "#simulate\n",
    "#fit reward, dynamic\n",
    "myilqr.fit(action, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad90532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea1362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F.hessian(my_reward, torch.rand((STATELEN+ACTLEN))\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4062449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8921)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "S = torch.rand((4))\n",
    "print(S[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d483ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(S.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f08e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(S.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca2265f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_S \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mts, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msl))\n\u001b[0;32m      2\u001b[0m new_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mal))\n\u001b[0;32m      4\u001b[0m my_Dyna \u001b[38;5;241m=\u001b[39m Dynamics(STATELEN \u001b[38;5;241m+\u001b[39m ACTLEN, STATELEN, STATELEN)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "new_S = torch.rand((4, 1, 3))\n",
    "new_A = torch.rand((4, 1, 5))\n",
    "\n",
    "my_Dyna = Dynamics(STATELEN + ACTLEN, STATELEN, STATELEN)\n",
    "my_reward = reward(STATELEN + ACTLEN, STATELEN , 1)\n",
    "\n",
    "s = S[0].clone().detach()\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i < self.ts:\n",
    "    new_S[i] = s\n",
    "    new_A[i] = (torch.matmul(new_S[i] - S[i],torch.transpose((K_arr[i]),0,1)) + \n",
    "         k_arr[i] + A[i]\n",
    "        )\n",
    "    sa_in = torch.cat((new_S[i], new_A[i]),dim = 1)\n",
    "    #sa_in shape = [1,state_size + action_size]\n",
    "\n",
    "    s = my_Dyna(sa_in)\n",
    "    #state shape = [1,state_size]\n",
    "\n",
    "    R[i] = my_reward(sa_in)\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7b8b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2503, 0.3700, 0.4463],\n",
      "         [0.4160, 0.0699, 0.1047]],\n",
      "\n",
      "        [[0.9365, 0.2305, 0.5194],\n",
      "         [0.5007, 0.1840, 0.7685]],\n",
      "\n",
      "        [[0.3118, 0.0037, 0.9661],\n",
      "         [0.8170, 0.1456, 0.4000]],\n",
      "\n",
      "        [[0.2563, 0.4554, 0.3776],\n",
      "         [0.1245, 0.0504, 0.4079]]])\n",
      "tensor([[[3.6793e-02, 1.1044e-01, 2.9308e-04, 4.6370e-01, 4.4860e-01],\n",
      "         [3.6057e-01, 9.2463e-03, 5.8263e-01, 5.1973e-01, 1.9103e-01]],\n",
      "\n",
      "        [[2.8883e-01, 3.3326e-01, 8.0322e-01, 9.9161e-01, 5.6124e-01],\n",
      "         [2.3160e-01, 5.5209e-02, 6.0231e-02, 1.4384e-02, 5.6236e-01]],\n",
      "\n",
      "        [[4.1703e-01, 1.2557e-01, 1.8472e-01, 7.6195e-01, 3.2007e-02],\n",
      "         [2.8687e-01, 4.0119e-01, 6.5657e-02, 4.1373e-01, 3.4538e-01]],\n",
      "\n",
      "        [[8.0777e-01, 2.9345e-01, 5.2441e-01, 6.9381e-01, 3.9671e-01],\n",
      "         [9.2216e-01, 5.5927e-01, 8.9263e-01, 2.1028e-01, 6.0275e-01]]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "new_S = torch.rand((4, 2, 3))\n",
    "new_A = torch.rand((4, 2, 5))\n",
    "print(new_S)\n",
    "print(new_A)\n",
    "sa_in = torch.cat((new_S[0], new_A[0]),dim = 1)\n",
    "print(np.shape(sa_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9b506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_Dyna = Dynamics(8, 3, 3)\n",
    "my_reward = reward(8, 3 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e141ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = my_Dyna(torch.cat((new_S[0], new_A[0]),dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73d74918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55d74156",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Tensor returned by the function given to hessian should contain a single element",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m C_t \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msa_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(C_t))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:807\u001b[0m, in \u001b[0;36mhessian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[0;32m    804\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[1;32m--> 807\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:574\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    571\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    572\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 574\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:803\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_jacobian_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;66;03m# or else the input will be detached\u001b[39;00m\n\u001b[0;32m    802\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp)\n\u001b[1;32m--> 803\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_single_output_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:574\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    571\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    572\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 574\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:794\u001b[0m, in \u001b[0;36mhessian.<locals>.ensure_single_output_function\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe function given to hessian should return a single Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnelement() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Tensor returned by the function given to hessian should contain a single element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The Tensor returned by the function given to hessian should contain a single element"
     ]
    }
   ],
   "source": [
    "import torch.autograd.functional as F\n",
    "C_t = F.hessian(my_reward, sa_in)\n",
    "print(np.shape(C_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "115224b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pow_adder_reducer() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m y\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpow_adder_reducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:807\u001b[0m, in \u001b[0;36mhessian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[0;32m    804\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[1;32m--> 807\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:574\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    571\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    572\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 574\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:803\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_jacobian_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;66;03m# or else the input will be detached\u001b[39;00m\n\u001b[0;32m    802\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp)\n\u001b[1;32m--> 803\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_single_output_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:574\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    571\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    572\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 574\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:786\u001b[0m, in \u001b[0;36mhessian.<locals>.ensure_single_output_function\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_single_output_function\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m--> 786\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m     is_out_tuple, t_out \u001b[38;5;241m=\u001b[39m _as_tuple(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhessian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    788\u001b[0m     _check_requires_grad(t_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "\u001b[1;31mTypeError\u001b[0m: pow_adder_reducer() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "import torch.autograd.functional as F\n",
    "def pow_adder_reducer(x, y):\n",
    "   return (2 * x.pow(2) + 3 * y.pow(2)).sum()\n",
    "inputs = torch.rand(2)\n",
    "F.hessian(pow_adder_reducer, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eba2266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def f(x, y):\n",
    "    return np.sin(np.sqrt(x ** 2 + y ** 2))\n",
    "\n",
    "x = np.linspace(-6, 6, 30)\n",
    "y = np.linspace(-6, 6, 30)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4809a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x7feb2bf0a190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "653460a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[17 22 27]\n",
      " [22 29 36]\n",
      " [27 36 45]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_ = np.array([[1,2,3],[4,5,6]])\n",
    "_x = x_.T\n",
    "print(_x)\n",
    "print(x_)\n",
    "x = np.matmul(_x,x_)\n",
    "print(x)\n",
    "w,v = np.linalg.eig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c0a5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.04026725e+01,  5.97327474e-01, -4.04484173e-15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538c0e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42866713, -0.80596391,  0.40824829],\n",
       "       [-0.56630692, -0.11238241, -0.81649658],\n",
       "       [-0.7039467 ,  0.58119908,  0.40824829]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009ed505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 22 27]\n",
      " [22 29 36]\n",
      " [27 36 45]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2327/3562604743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "np.linalg.inv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90278ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import vmap\n",
    "N = 5\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "x = torch.randn(N, requires_grad=True)\n",
    "y = f(x)\n",
    "basis_vectors = torch.eye(N)\n",
    "\n",
    "# Sequential approach\n",
    "jacobian_rows = [torch.autograd.grad(y, x, v, retain_graph=True)[0]\n",
    "                 for v in basis_vectors.unbind()]\n",
    "jacobian = torch.stack(jacobian_rows)\n",
    "\n",
    "# Using `vmap`, we can vectorize the whole computation, computing the\n",
    "# Jacobian in a single call to `autograd.grad`.\n",
    "def get_vjp(v):\n",
    "    return torch.autograd.grad(y, x, v)[0]\n",
    "\n",
    "jacobian_vmap = vmap(get_vjp)(basis_vectors)\n",
    "assert torch.allclose(jacobian_vmap, jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee053c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4d683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a54d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hessian = vmap(hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc7bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3185c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4696, -1.2516, -0.3284],\n",
       "        [ 3.3134,  1.2970, -1.6440]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                     # [D], [D] -> []\n",
    "batched_dot = functorch.vmap(functorch.vmap(torch.dot))  # [N1, N0, D], [N1, N0, D] -> [N1, N0]\n",
    "x, y = torch.randn(2, 3, 5), torch.randn(2, 3, 5)\n",
    "batched_dot(x, y) # tensor of size [2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f50b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2970)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x[1][1], y[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f619af59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0678,  0.7170, -0.2483,  1.3951, -0.2144])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815e8774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor1 = torch.randn(10, 1, 4)\n",
    "tensor2 = torch.randn(10, 4, 4)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "755c1d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.unsqueeze(3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a29067ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1])\n",
      "tensor([-0.6278], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b_s = 3\n",
    "al = 4\n",
    "sl = 5\n",
    "my_reward = reward(sl, sl, al**2 + al + 1)\n",
    "\n",
    "def _get_reward(state_action):\n",
    "        \n",
    "        state, action = torch.split(state_action, [sl, al], dim=-1)\n",
    "        pre_psd, bias, value = torch.split(my_reward(state), [al**2, al, 1], dim=-1)\n",
    "        pre_psd = torch.reshape(pre_psd, (al, al))\n",
    "        pre_psd_trans = torch.transpose(pre_psd, 0, 1)\n",
    "        psd = torch.matmul(pre_psd, pre_psd_trans)\n",
    "        \n",
    "        a_b = (action - bias).unsqueeze(1)\n",
    "        print(a_b.size())\n",
    "        a_b_t = torch.transpose(a_b,0,1)\n",
    "        print(a_b_t.size())\n",
    "        print(torch.matmul(torch.matmul(a_b_t,psd),a_b).squeeze(-1).size())\n",
    "        return value - torch.matmul(torch.matmul(a_b_t,psd),a_b).squeeze(-1)\n",
    "\n",
    "action = torch.rand((1, al))\n",
    "state = torch.zeros((1, sl))\n",
    "sain = torch.cat((state[0], action[0]),dim = 0)\n",
    "print(_get_reward(sain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62600dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "newrew = vmap(_get_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c6a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
